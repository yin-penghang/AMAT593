{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbors\n",
    "\n",
    "We use KNNs to create a model that directly predicts a class for a new data point based off of the features. We'll also introduce metric learning to improve the performance of KNN classifiers by constructing informed distance metric."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basics\n",
    "\n",
    "Although KNNs use labelled data for inference, **they do not go through any training process because there are no model parameters to learn.** KNNs can be used for both classification (`KNeighborsClassifier`) and regression (`KNeighborsRegressor`) tasks.\n",
    "\n",
    "Given a labeled dataset $\\{(x_i, y_i)\\}_{i=1}^n$ and a sample $x$ to be predicted:\n",
    "\n",
    "1. Select a value $K$ and a **distance function**\n",
    "\n",
    "2. Compute the distance between $x$ and the $n$ training samples\n",
    "\n",
    "3. Take the $K$-nearest data samples, known as $K$-nearest neighbors\n",
    "\n",
    "4. - Classification: assign $x$ to the class that has the greatest number of its $K$-nearest neighbors\n",
    "   - Regression: average the target values of its $K$-nearest neighbors\n",
    "\n",
    "<img src='../figs/08_KNN.png' width = '300'>\n",
    "\n",
    "KNN's performance is influenced by \n",
    "\n",
    "* The **distance function** used to determine the nearest neighbors\n",
    "\n",
    "* **number of nearest neighbors** taken into account, i.e. value of $K$, used to classify  new samples\n",
    "\n",
    "\n",
    "In the case where variables have very different measurement scales, then one variable will have a much higher influence on the distance calculated than another, e.g., one variable is based on annual income in dollars, and the other is based on age in years. We need to **standardize** the data (training and testing) so that features are on the same scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "Set index_col=0 to use the first column as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>995</td>\n",
       "      <td>1.010953</td>\n",
       "      <td>1.034006</td>\n",
       "      <td>0.853116</td>\n",
       "      <td>0.622460</td>\n",
       "      <td>1.036610</td>\n",
       "      <td>0.586240</td>\n",
       "      <td>0.746811</td>\n",
       "      <td>0.319752</td>\n",
       "      <td>1.117340</td>\n",
       "      <td>1.348517</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>996</td>\n",
       "      <td>0.575529</td>\n",
       "      <td>0.955786</td>\n",
       "      <td>0.941835</td>\n",
       "      <td>0.792882</td>\n",
       "      <td>1.414277</td>\n",
       "      <td>1.269540</td>\n",
       "      <td>1.055928</td>\n",
       "      <td>0.713193</td>\n",
       "      <td>0.958684</td>\n",
       "      <td>1.663489</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>997</td>\n",
       "      <td>1.135470</td>\n",
       "      <td>0.982462</td>\n",
       "      <td>0.781905</td>\n",
       "      <td>0.916738</td>\n",
       "      <td>0.901031</td>\n",
       "      <td>0.884738</td>\n",
       "      <td>0.386802</td>\n",
       "      <td>0.389584</td>\n",
       "      <td>0.919191</td>\n",
       "      <td>1.385504</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>998</td>\n",
       "      <td>1.084894</td>\n",
       "      <td>0.861769</td>\n",
       "      <td>0.407158</td>\n",
       "      <td>0.665696</td>\n",
       "      <td>1.608612</td>\n",
       "      <td>0.943859</td>\n",
       "      <td>0.855806</td>\n",
       "      <td>1.061338</td>\n",
       "      <td>1.277456</td>\n",
       "      <td>1.188063</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>999</td>\n",
       "      <td>0.837460</td>\n",
       "      <td>0.961184</td>\n",
       "      <td>0.417006</td>\n",
       "      <td>0.799784</td>\n",
       "      <td>0.934399</td>\n",
       "      <td>0.424762</td>\n",
       "      <td>0.778234</td>\n",
       "      <td>0.907962</td>\n",
       "      <td>1.257190</td>\n",
       "      <td>1.364837</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       WTT       PTI       EQW       SBI       LQE       QWG  \\\n",
       "0             0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608   \n",
       "1             1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450   \n",
       "2             2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781   \n",
       "3             3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128   \n",
       "4             4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727   \n",
       "..          ...       ...       ...       ...       ...       ...       ...   \n",
       "995         995  1.010953  1.034006  0.853116  0.622460  1.036610  0.586240   \n",
       "996         996  0.575529  0.955786  0.941835  0.792882  1.414277  1.269540   \n",
       "997         997  1.135470  0.982462  0.781905  0.916738  0.901031  0.884738   \n",
       "998         998  1.084894  0.861769  0.407158  0.665696  1.608612  0.943859   \n",
       "999         999  0.837460  0.961184  0.417006  0.799784  0.934399  0.424762   \n",
       "\n",
       "          FDJ       PJF       HQE       NXJ  TARGET CLASS  \n",
       "0    0.759697  0.643798  0.879422  1.231409             1  \n",
       "1    0.675334  1.013546  0.621552  1.492702             0  \n",
       "2    1.626351  1.154483  0.957877  1.285597             0  \n",
       "3    1.409708  1.380003  1.522692  1.153093             1  \n",
       "4    1.115596  0.646691  1.463812  1.419167             1  \n",
       "..        ...       ...       ...       ...           ...  \n",
       "995  0.746811  0.319752  1.117340  1.348517             1  \n",
       "996  1.055928  0.713193  0.958684  1.663489             0  \n",
       "997  0.386802  0.389584  0.919191  1.385504             1  \n",
       "998  0.855806  1.061338  1.277456  1.188063             1  \n",
       "999  0.778234  0.907962  1.257190  1.364837             1  \n",
       "\n",
       "[1000 rows x 12 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"KNN_Dataset\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"KNN_Dataset\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "      <th>TARGET CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.913917</td>\n",
       "      <td>1.162073</td>\n",
       "      <td>0.567946</td>\n",
       "      <td>0.755464</td>\n",
       "      <td>0.780862</td>\n",
       "      <td>0.352608</td>\n",
       "      <td>0.759697</td>\n",
       "      <td>0.643798</td>\n",
       "      <td>0.879422</td>\n",
       "      <td>1.231409</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.635632</td>\n",
       "      <td>1.003722</td>\n",
       "      <td>0.535342</td>\n",
       "      <td>0.825645</td>\n",
       "      <td>0.924109</td>\n",
       "      <td>0.648450</td>\n",
       "      <td>0.675334</td>\n",
       "      <td>1.013546</td>\n",
       "      <td>0.621552</td>\n",
       "      <td>1.492702</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.721360</td>\n",
       "      <td>1.201493</td>\n",
       "      <td>0.921990</td>\n",
       "      <td>0.855595</td>\n",
       "      <td>1.526629</td>\n",
       "      <td>0.720781</td>\n",
       "      <td>1.626351</td>\n",
       "      <td>1.154483</td>\n",
       "      <td>0.957877</td>\n",
       "      <td>1.285597</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.234204</td>\n",
       "      <td>1.386726</td>\n",
       "      <td>0.653046</td>\n",
       "      <td>0.825624</td>\n",
       "      <td>1.142504</td>\n",
       "      <td>0.875128</td>\n",
       "      <td>1.409708</td>\n",
       "      <td>1.380003</td>\n",
       "      <td>1.522692</td>\n",
       "      <td>1.153093</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.279491</td>\n",
       "      <td>0.949750</td>\n",
       "      <td>0.627280</td>\n",
       "      <td>0.668976</td>\n",
       "      <td>1.232537</td>\n",
       "      <td>0.703727</td>\n",
       "      <td>1.115596</td>\n",
       "      <td>0.646691</td>\n",
       "      <td>1.463812</td>\n",
       "      <td>1.419167</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0  0.913917  1.162073  0.567946  0.755464  0.780862  0.352608  0.759697   \n",
       "1  0.635632  1.003722  0.535342  0.825645  0.924109  0.648450  0.675334   \n",
       "2  0.721360  1.201493  0.921990  0.855595  1.526629  0.720781  1.626351   \n",
       "3  1.234204  1.386726  0.653046  0.825624  1.142504  0.875128  1.409708   \n",
       "4  1.279491  0.949750  0.627280  0.668976  1.232537  0.703727  1.115596   \n",
       "\n",
       "        PJF       HQE       NXJ  TARGET CLASS  \n",
       "0  0.643798  0.879422  1.231409             1  \n",
       "1  1.013546  0.621552  1.492702             0  \n",
       "2  1.154483  0.957877  1.285597             0  \n",
       "3  1.380003  1.522692  1.153093             1  \n",
       "4  0.646691  1.463812  1.419167             1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the Variables\n",
    "\n",
    "Because the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the observations, and hence on the KNN classifier, than variables that are on a small scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>StandardScaler()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(df.drop('TARGET CLASS',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_features = scaler.transform(df.drop('TARGET CLASS',axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WTT</th>\n",
       "      <th>PTI</th>\n",
       "      <th>EQW</th>\n",
       "      <th>SBI</th>\n",
       "      <th>LQE</th>\n",
       "      <th>QWG</th>\n",
       "      <th>FDJ</th>\n",
       "      <th>PJF</th>\n",
       "      <th>HQE</th>\n",
       "      <th>NXJ</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.123542</td>\n",
       "      <td>0.185907</td>\n",
       "      <td>-0.913431</td>\n",
       "      <td>0.319629</td>\n",
       "      <td>-1.033637</td>\n",
       "      <td>-2.308375</td>\n",
       "      <td>-0.798951</td>\n",
       "      <td>-1.482368</td>\n",
       "      <td>-0.949719</td>\n",
       "      <td>-0.643314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.084836</td>\n",
       "      <td>-0.430348</td>\n",
       "      <td>-1.025313</td>\n",
       "      <td>0.625388</td>\n",
       "      <td>-0.444847</td>\n",
       "      <td>-1.152706</td>\n",
       "      <td>-1.129797</td>\n",
       "      <td>-0.202240</td>\n",
       "      <td>-1.828051</td>\n",
       "      <td>0.636759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.788702</td>\n",
       "      <td>0.339318</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.755873</td>\n",
       "      <td>2.031693</td>\n",
       "      <td>-0.870156</td>\n",
       "      <td>2.599818</td>\n",
       "      <td>0.285707</td>\n",
       "      <td>-0.682494</td>\n",
       "      <td>-0.377850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.982841</td>\n",
       "      <td>1.060193</td>\n",
       "      <td>-0.621399</td>\n",
       "      <td>0.625299</td>\n",
       "      <td>0.452820</td>\n",
       "      <td>-0.267220</td>\n",
       "      <td>1.750208</td>\n",
       "      <td>1.066491</td>\n",
       "      <td>1.241325</td>\n",
       "      <td>-1.026987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.139275</td>\n",
       "      <td>-0.640392</td>\n",
       "      <td>-0.709819</td>\n",
       "      <td>-0.057175</td>\n",
       "      <td>0.822886</td>\n",
       "      <td>-0.936773</td>\n",
       "      <td>0.596782</td>\n",
       "      <td>-1.472352</td>\n",
       "      <td>1.040772</td>\n",
       "      <td>0.276510</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        WTT       PTI       EQW       SBI       LQE       QWG       FDJ  \\\n",
       "0 -0.123542  0.185907 -0.913431  0.319629 -1.033637 -2.308375 -0.798951   \n",
       "1 -1.084836 -0.430348 -1.025313  0.625388 -0.444847 -1.152706 -1.129797   \n",
       "2 -0.788702  0.339318  0.301511  0.755873  2.031693 -0.870156  2.599818   \n",
       "3  0.982841  1.060193 -0.621399  0.625299  0.452820 -0.267220  1.750208   \n",
       "4  1.139275 -0.640392 -0.709819 -0.057175  0.822886 -0.936773  0.596782   \n",
       "\n",
       "        PJF       HQE       NXJ  \n",
       "0 -1.482368 -0.949719 -0.643314  \n",
       "1 -0.202240 -1.828051  0.636759  \n",
       "2  0.285707 -0.682494 -0.377850  \n",
       "3  1.066491  1.241325 -1.026987  \n",
       "4 -1.472352  1.040772  0.276510  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1])\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,df['TARGET CLASS'],\n",
    "                                                    test_size=0.30, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KNN\n",
    "\n",
    "Remember that we are trying to come up with a model to predict whether someone will TARGET CLASS or not. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For KNN algorithm, there are two important factors: the number of nearest neighbors and the metric or norm used for measure the distance, i.e., $\\ell_p$ norm ($p\\geq1$)\n",
    "\n",
    "* Euclidean:  $\\|x-z\\|:=\\sqrt{\\sum_{i=1}^d  (x_i - z_i)^2 }$, $(p=2)$\n",
    "\n",
    "* Manhattan: $\\|x-z\\|_1:=\\sum_{i=1}^d  |x_i - z_i|$, $(p=1)$\n",
    "\n",
    "* Minkowski: $\\|x-z\\|_p := \\left(\\sum_{i=1}^d  (x_i - z_i)^p \\right)^{1/p}$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1) # default: Euclidean distance, i.e., p=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=1\n",
      "[[151   8]\n",
      " [ 15 126]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.95      0.93       159\n",
      "           1       0.94      0.89      0.92       141\n",
      "\n",
      "    accuracy                           0.92       300\n",
      "   macro avg       0.92      0.92      0.92       300\n",
      "weighted avg       0.92      0.92      0.92       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('K=1')\n",
    "# confusion matrix: [ [#TP, #FP], [#FN, #TN] ] \n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a K Value\n",
    "\n",
    "Do a for loop to pick a good K Value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test)) # misclassification rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the error rate tends to hover around 0.05-0.07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best K = 34\n",
      "[[153   6]\n",
      " [  7 134]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       159\n",
      "           1       0.96      0.95      0.95       141\n",
      "\n",
      "    accuracy                           0.96       300\n",
      "   macro avg       0.96      0.96      0.96       300\n",
      "weighted avg       0.96      0.96      0.96       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# The best K = 34\n",
    "knn = KNeighborsClassifier(n_neighbors=34)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('The best K = 34')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Margin Nearest Neighbor\n",
    "\n",
    "[Large Margin Nearest Neighbor](https://en.wikipedia.org/wiki/Large_margin_nearest_neighbor) (LMNN) belongs to the class of metric learning. The goal of supervised metric learning algorithms is to transform points in a new space, in which \n",
    "\n",
    "* the distance between two points from the same class will be small\n",
    "\n",
    "* the distance between two points from different classes will be large.\n",
    "\n",
    "LMNN learns a **Mahalanobis distance** metric in the KNN classification setting. The learned metric attempts to keep close k-nearest neighbors from the same class, while keeping examples from different classes separated by a large margin. This algorithm makes no assumptions about the distribution of the data. **You'll need to first install the ``metric_learn`` library.**\n",
    "\n",
    "A **Mahalanobis distance** metric is induced by some matrix $\\mathbf{D}$:\n",
    "\n",
    "$$\n",
    "d_M(\\mathbf{x}, \\mathbf{z}) = \\|\\mathbf{D}(\\mathbf{x} - \\mathbf{z})\\|\n",
    "$$\n",
    "\n",
    "<img src='../figs/08_Lmnn.png' width =  '600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distance matrix, i.e. $\\mathbf{D}\\in\\mathbb{R}^{d\\times d}$, is learned by solving the following optimization problem:\n",
    "\n",
    "$$\n",
    "\\min_{\\mathbf{D}\\in\\mathbb{R}^{d\\times d}} \\sum_{i}\\sum_{j\\in\\mathcal{N}(i)} \\eta_{i,j} \\|\\mathbf{D}(\\mathbf{x}_i - \\mathbf{x}_j)\\|^2 + c \\sum_{i}\\sum_{j,l\\in\\mathcal{N}(i)} \\eta_{i,j} (1-\\eta_{i,l})\\left[ 1+ \\|\\mathbf{D}(\\mathbf{x}_i - \\mathbf{x}_j)\\|^2 - \\|\\mathbf{D}(\\mathbf{x}_i - \\mathbf{x}_l)\\|^2\\right]_+\n",
    "$$\n",
    "\n",
    "where $\\mathbf{x}_i$ is a data point, $\\mathbf{x}_j$ is one of its K-nearest neighbors sharing the same label, and $\\mathbf{x}_l$ is any instance within that region with different label, $\\eta_{i,j}\\in\\{0,1\\}$ is the indicator, $\\eta_{i,j} = 1$ represents $\\mathbf{x}_j$ is the K-nearest neighbors (with same labels) of $\\mathbf{x}_i$, $\\eta_{i,l}=0$ indicates $\\mathbf{x}_i$, $\\mathbf{x}_l$ belong to different classes, $[\\cdot]_+ = \\max(0,\\cdot)$ is the hinge loss.\n",
    "\n",
    "* The first optimization goal is achieved by minimizing the average distance between instances and their target neighbors of the same class.\n",
    "\n",
    "* The second goal is achieved by penalizing distances to $\\mathbf{x}_l$ that are less than one unit further away than to target neighbors $\\mathbf{x}_j$ (and therefore pushing them out of the local neighborhood of $\\mathbf{x}_i$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from metric_learn import LMNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"â–¸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"â–¾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LMNN(k=5, learn_rate=1e-06)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LMNN</label><div class=\"sk-toggleable__content\"><pre>LMNN(k=5, learn_rate=1e-06)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LMNN(k=5, learn_rate=1e-06)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lmnn = LMNN(k=5, learn_rate=1e-6)\n",
    "lmnn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<function MahalanobisMixin.get_metric.<locals>.metric_fun at 0x7f78ad41e1f0>\n"
     ]
    }
   ],
   "source": [
    "print(lmnn.get_metric())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K=5\n",
      "[[154   5]\n",
      " [ 11 130]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.97      0.95       159\n",
      "           1       0.96      0.92      0.94       141\n",
      "\n",
      "    accuracy                           0.95       300\n",
      "   macro avg       0.95      0.95      0.95       300\n",
      "weighted avg       0.95      0.95      0.95       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric=lmnn.get_metric())\n",
    "knn.fit(X_train,y_train)\n",
    "\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('K=5')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Error Rate')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "error_rate = []\n",
    "\n",
    "for i in range(1,40):\n",
    "    lmnn = LMNN(k=i, learn_rate=1e-6)\n",
    "    lmnn.fit(X_train, y_train)\n",
    "    knn = KNeighborsClassifier(n_neighbors=i, metric=lmnn.get_metric())\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test)) # misclassification rate\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10)\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**KNN with data-driven metric learning outperforms the original KNN with standard metrics at different levels of K value.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting Age of Abalone\n",
    "\n",
    "The [Abalone dataset](https://archive.ics.uci.edu/ml/datasets/abalone) contains age measurements on a large number of abalones. The age of an [abalone](https://en.wikipedia.org/wiki/Abalone) can be found by cutting its shell and counting the number of rings on the shell. \n",
    "\n",
    "This is a **regression** problem.\n",
    "\n",
    "\n",
    "### Attribute Information:\n",
    "\n",
    "Given is the attribute name, attribute type, the measurement unit and a brief description. The number of rings is the value to predict: \n",
    "\n",
    "- Sex: nominal / -- / M, F, and I (infant) \n",
    "- Length: continuous / mm / Longest shell measurement \n",
    "- Diameter: continuous / mm / perpendicular to length \n",
    "- Height: continuous / mm / with meat in shell \n",
    "- Whole weight: continuous / grams / whole abalone \n",
    "- Shucked weight: continuous / grams / weight of meat \n",
    "- Viscera weight: continuous / grams / gut weight (after bleeding) \n",
    "- Shell weight: continuous / grams / after being dried \n",
    "- Rings: integer / -- / +1.5 gives the age in years \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/abalone/abalone.data\"\n",
    "abalone = pd.read_csv(url, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.150</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.070</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.210</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.155</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.055</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0      1      2      3       4       5       6      7   8\n",
       "0  M  0.455  0.365  0.095  0.5140  0.2245  0.1010  0.150  15\n",
       "1  M  0.350  0.265  0.090  0.2255  0.0995  0.0485  0.070   7\n",
       "2  F  0.530  0.420  0.135  0.6770  0.2565  0.1415  0.210   9\n",
       "3  M  0.440  0.365  0.125  0.5160  0.2155  0.1140  0.155  10\n",
       "4  I  0.330  0.255  0.080  0.2050  0.0895  0.0395  0.055   7"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add feature names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone.columns = [\n",
    "    \"Sex\",\n",
    "    \"Length\",\n",
    "    \"Diameter\",\n",
    "    \"Height\",\n",
    "    \"Whole weight\",\n",
    "    \"Shucked weight\",\n",
    "    \"Viscera weight\",\n",
    "    \"Shell weight\",\n",
    "    \"Rings\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Length</th>\n",
       "      <th>Diameter</th>\n",
       "      <th>Height</th>\n",
       "      <th>Whole weight</th>\n",
       "      <th>Shucked weight</th>\n",
       "      <th>Viscera weight</th>\n",
       "      <th>Shell weight</th>\n",
       "      <th>Rings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>M</td>\n",
       "      <td>0.455</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.095</td>\n",
       "      <td>0.5140</td>\n",
       "      <td>0.2245</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.1500</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>M</td>\n",
       "      <td>0.350</td>\n",
       "      <td>0.265</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.2255</td>\n",
       "      <td>0.0995</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0700</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>F</td>\n",
       "      <td>0.530</td>\n",
       "      <td>0.420</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.6770</td>\n",
       "      <td>0.2565</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.2100</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>M</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.365</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.5160</td>\n",
       "      <td>0.2155</td>\n",
       "      <td>0.1140</td>\n",
       "      <td>0.1550</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.080</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4172</th>\n",
       "      <td>F</td>\n",
       "      <td>0.565</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.165</td>\n",
       "      <td>0.8870</td>\n",
       "      <td>0.3700</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>0.2490</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4173</th>\n",
       "      <td>M</td>\n",
       "      <td>0.590</td>\n",
       "      <td>0.440</td>\n",
       "      <td>0.135</td>\n",
       "      <td>0.9660</td>\n",
       "      <td>0.4390</td>\n",
       "      <td>0.2145</td>\n",
       "      <td>0.2605</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4174</th>\n",
       "      <td>M</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.205</td>\n",
       "      <td>1.1760</td>\n",
       "      <td>0.5255</td>\n",
       "      <td>0.2875</td>\n",
       "      <td>0.3080</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>F</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.485</td>\n",
       "      <td>0.150</td>\n",
       "      <td>1.0945</td>\n",
       "      <td>0.5310</td>\n",
       "      <td>0.2610</td>\n",
       "      <td>0.2960</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4176</th>\n",
       "      <td>M</td>\n",
       "      <td>0.710</td>\n",
       "      <td>0.555</td>\n",
       "      <td>0.195</td>\n",
       "      <td>1.9485</td>\n",
       "      <td>0.9455</td>\n",
       "      <td>0.3765</td>\n",
       "      <td>0.4950</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4177 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sex  Length  Diameter  Height  Whole weight  Shucked weight  \\\n",
       "0      M   0.455     0.365   0.095        0.5140          0.2245   \n",
       "1      M   0.350     0.265   0.090        0.2255          0.0995   \n",
       "2      F   0.530     0.420   0.135        0.6770          0.2565   \n",
       "3      M   0.440     0.365   0.125        0.5160          0.2155   \n",
       "4      I   0.330     0.255   0.080        0.2050          0.0895   \n",
       "...   ..     ...       ...     ...           ...             ...   \n",
       "4172   F   0.565     0.450   0.165        0.8870          0.3700   \n",
       "4173   M   0.590     0.440   0.135        0.9660          0.4390   \n",
       "4174   M   0.600     0.475   0.205        1.1760          0.5255   \n",
       "4175   F   0.625     0.485   0.150        1.0945          0.5310   \n",
       "4176   M   0.710     0.555   0.195        1.9485          0.9455   \n",
       "\n",
       "      Viscera weight  Shell weight  Rings  \n",
       "0             0.1010        0.1500     15  \n",
       "1             0.0485        0.0700      7  \n",
       "2             0.1415        0.2100      9  \n",
       "3             0.1140        0.1550     10  \n",
       "4             0.0395        0.0550      7  \n",
       "...              ...           ...    ...  \n",
       "4172          0.2390        0.2490     11  \n",
       "4173          0.2145        0.2605     10  \n",
       "4174          0.2875        0.3080      9  \n",
       "4175          0.2610        0.2960     10  \n",
       "4176          0.3765        0.4950     12  \n",
       "\n",
       "[4177 rows x 9 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abalone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since sex is not a purely physical measure, we remove it from the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "abalone = abalone.drop(\"Sex\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The target variable is Rings. A histogram will give a quick and useful overview of the age ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "abalone[\"Rings\"].hist(bins=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = abalone.drop(\"Rings\", axis=1)\n",
    "y = abalone[\"Rings\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ``MinMaxScalar`` to normalize data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler.fit(X)\n",
    "X_scaler = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaler, y, test_size=0.2, random_state=12345\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "knn_model = KNeighborsRegressor(n_neighbors=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  2.3861364161083864\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "test_preds = knn_model.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, test_preds)\n",
    "print('Test RMSE: ', np.sqrt(test_mse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can improve the performance using cross validation ``GridSearchCV`` to select hyperparameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 98 candidates, totalling 490 fits\n",
      "[CV 1/5] END ................n_neighbors=1, p=1;, score=0.188 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=1, p=1;, score=0.148 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=1, p=1;, score=0.135 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=1, p=1;, score=0.164 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=1, p=1;, score=0.215 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=1, p=2;, score=0.122 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=1, p=2;, score=0.189 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=1, p=2;, score=0.184 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=1, p=2;, score=0.195 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=1, p=2;, score=0.241 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=2, p=1;, score=0.341 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=2, p=1;, score=0.394 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=2, p=1;, score=0.374 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=2, p=1;, score=0.371 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=2, p=1;, score=0.393 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=2, p=2;, score=0.319 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=2, p=2;, score=0.399 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=2, p=2;, score=0.384 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=2, p=2;, score=0.367 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=2, p=2;, score=0.391 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=3, p=1;, score=0.383 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=3, p=1;, score=0.435 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=3, p=1;, score=0.470 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=3, p=1;, score=0.453 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=3, p=1;, score=0.427 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=3, p=2;, score=0.369 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=3, p=2;, score=0.473 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=3, p=2;, score=0.473 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=3, p=2;, score=0.438 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=3, p=2;, score=0.455 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=4, p=1;, score=0.420 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=4, p=1;, score=0.458 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=4, p=1;, score=0.485 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=4, p=1;, score=0.470 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=4, p=1;, score=0.462 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=4, p=2;, score=0.406 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=4, p=2;, score=0.487 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=4, p=2;, score=0.486 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=4, p=2;, score=0.477 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=4, p=2;, score=0.490 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=5, p=1;, score=0.436 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=5, p=1;, score=0.477 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=5, p=1;, score=0.497 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=5, p=1;, score=0.507 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=5, p=1;, score=0.486 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=5, p=2;, score=0.435 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=5, p=2;, score=0.506 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=5, p=2;, score=0.513 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=5, p=2;, score=0.495 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=5, p=2;, score=0.499 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=6, p=1;, score=0.458 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=6, p=1;, score=0.491 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=6, p=1;, score=0.504 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=6, p=1;, score=0.524 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=6, p=1;, score=0.502 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=6, p=2;, score=0.466 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=6, p=2;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=6, p=2;, score=0.526 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=6, p=2;, score=0.516 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=6, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=7, p=1;, score=0.466 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=7, p=1;, score=0.495 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=7, p=1;, score=0.515 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=7, p=1;, score=0.537 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=7, p=1;, score=0.512 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=7, p=2;, score=0.488 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=7, p=2;, score=0.516 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=7, p=2;, score=0.528 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=7, p=2;, score=0.526 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=7, p=2;, score=0.537 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=8, p=1;, score=0.477 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=8, p=1;, score=0.507 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=8, p=1;, score=0.510 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=8, p=1;, score=0.536 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=8, p=1;, score=0.520 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=8, p=2;, score=0.488 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=8, p=2;, score=0.517 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=8, p=2;, score=0.531 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=8, p=2;, score=0.546 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=8, p=2;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=9, p=1;, score=0.489 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=9, p=1;, score=0.515 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=9, p=1;, score=0.513 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=9, p=1;, score=0.537 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=9, p=1;, score=0.527 total time=   0.0s\n",
      "[CV 1/5] END ................n_neighbors=9, p=2;, score=0.494 total time=   0.0s\n",
      "[CV 2/5] END ................n_neighbors=9, p=2;, score=0.516 total time=   0.0s\n",
      "[CV 3/5] END ................n_neighbors=9, p=2;, score=0.537 total time=   0.0s\n",
      "[CV 4/5] END ................n_neighbors=9, p=2;, score=0.540 total time=   0.0s\n",
      "[CV 5/5] END ................n_neighbors=9, p=2;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=10, p=1;, score=0.497 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=10, p=1;, score=0.516 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=10, p=1;, score=0.517 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=10, p=1;, score=0.538 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=10, p=1;, score=0.537 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=10, p=2;, score=0.494 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=10, p=2;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=10, p=2;, score=0.535 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=10, p=2;, score=0.540 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=10, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=11, p=1;, score=0.499 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=11, p=1;, score=0.522 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=11, p=1;, score=0.524 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=11, p=1;, score=0.539 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=11, p=1;, score=0.539 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=11, p=2;, score=0.495 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=11, p=2;, score=0.525 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=11, p=2;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=11, p=2;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=11, p=2;, score=0.547 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=12, p=1;, score=0.505 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=12, p=1;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=12, p=1;, score=0.527 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=12, p=1;, score=0.542 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 5/5] END ...............n_neighbors=12, p=1;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=12, p=2;, score=0.492 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=12, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=12, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=12, p=2;, score=0.547 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=12, p=2;, score=0.547 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=13, p=1;, score=0.503 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=13, p=1;, score=0.526 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=13, p=1;, score=0.529 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=13, p=1;, score=0.545 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=13, p=1;, score=0.554 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=13, p=2;, score=0.502 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=13, p=2;, score=0.526 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=13, p=2;, score=0.532 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=13, p=2;, score=0.545 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=13, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=14, p=1;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=14, p=1;, score=0.529 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=14, p=1;, score=0.529 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=14, p=1;, score=0.549 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=14, p=1;, score=0.554 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=14, p=2;, score=0.502 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=14, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=14, p=2;, score=0.535 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=14, p=2;, score=0.548 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=14, p=2;, score=0.551 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=15, p=1;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=15, p=1;, score=0.529 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=15, p=1;, score=0.524 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=15, p=1;, score=0.551 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=15, p=1;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=15, p=2;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=15, p=2;, score=0.520 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=15, p=2;, score=0.531 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=15, p=2;, score=0.544 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=15, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=16, p=1;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=16, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=16, p=1;, score=0.525 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=16, p=1;, score=0.549 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=16, p=1;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=16, p=2;, score=0.509 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=16, p=2;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=16, p=2;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=16, p=2;, score=0.548 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=16, p=2;, score=0.546 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=17, p=1;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=17, p=1;, score=0.530 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=17, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=17, p=1;, score=0.552 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=17, p=1;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=17, p=2;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=17, p=2;, score=0.518 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=17, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=17, p=2;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=17, p=2;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=18, p=1;, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=18, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=18, p=1;, score=0.527 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=18, p=1;, score=0.552 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=18, p=1;, score=0.551 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=18, p=2;, score=0.512 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=18, p=2;, score=0.523 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=18, p=2;, score=0.529 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=18, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=18, p=2;, score=0.553 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=19, p=1;, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=19, p=1;, score=0.529 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=19, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=19, p=1;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=19, p=1;, score=0.558 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=19, p=2;, score=0.510 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=19, p=2;, score=0.526 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=19, p=2;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=19, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=19, p=2;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=20, p=1;, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=20, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=20, p=1;, score=0.532 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=20, p=1;, score=0.547 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=20, p=1;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=20, p=2;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=20, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=20, p=2;, score=0.532 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=20, p=2;, score=0.550 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=20, p=2;, score=0.553 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=21, p=1;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=21, p=1;, score=0.531 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=21, p=1;, score=0.530 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=21, p=1;, score=0.546 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=21, p=1;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=21, p=2;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=21, p=2;, score=0.523 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=21, p=2;, score=0.529 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=21, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=21, p=2;, score=0.555 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=22, p=1;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=22, p=1;, score=0.532 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=22, p=1;, score=0.530 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=22, p=1;, score=0.544 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=22, p=1;, score=0.554 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=22, p=2;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=22, p=2;, score=0.522 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=22, p=2;, score=0.532 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=22, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=22, p=2;, score=0.555 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=23, p=1;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=23, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=23, p=1;, score=0.529 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=23, p=1;, score=0.543 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=23, p=1;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=23, p=2;, score=0.505 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=23, p=2;, score=0.523 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............n_neighbors=23, p=2;, score=0.529 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=23, p=2;, score=0.545 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=23, p=2;, score=0.558 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=24, p=1;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=24, p=1;, score=0.532 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=24, p=1;, score=0.531 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=24, p=1;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=24, p=1;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=24, p=2;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=24, p=2;, score=0.523 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=24, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=24, p=2;, score=0.544 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=24, p=2;, score=0.559 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=25, p=1;, score=0.509 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=25, p=1;, score=0.532 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=25, p=1;, score=0.531 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=25, p=1;, score=0.540 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=25, p=1;, score=0.555 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=25, p=2;, score=0.505 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=25, p=2;, score=0.523 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=25, p=2;, score=0.529 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=25, p=2;, score=0.546 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=25, p=2;, score=0.558 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=26, p=1;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=26, p=1;, score=0.530 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=26, p=1;, score=0.530 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=26, p=1;, score=0.541 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=26, p=1;, score=0.552 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=26, p=2;, score=0.503 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=26, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=26, p=2;, score=0.533 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=26, p=2;, score=0.544 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=26, p=2;, score=0.559 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=27, p=1;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=27, p=1;, score=0.532 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=27, p=1;, score=0.529 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=27, p=1;, score=0.540 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=27, p=1;, score=0.551 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=27, p=2;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=27, p=2;, score=0.527 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=27, p=2;, score=0.534 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=27, p=2;, score=0.543 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=27, p=2;, score=0.559 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=28, p=1;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=28, p=1;, score=0.533 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=28, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=28, p=1;, score=0.541 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=28, p=1;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=28, p=2;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=28, p=2;, score=0.527 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=28, p=2;, score=0.531 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=28, p=2;, score=0.543 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=28, p=2;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=29, p=1;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=29, p=1;, score=0.530 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=29, p=1;, score=0.527 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=29, p=1;, score=0.540 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=29, p=1;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=29, p=2;, score=0.511 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=29, p=2;, score=0.527 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=29, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=29, p=2;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=29, p=2;, score=0.557 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=30, p=1;, score=0.509 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=30, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=30, p=1;, score=0.526 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=30, p=1;, score=0.539 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=30, p=1;, score=0.547 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=30, p=2;, score=0.512 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=30, p=2;, score=0.528 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=30, p=2;, score=0.528 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=30, p=2;, score=0.542 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=30, p=2;, score=0.557 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=31, p=1;, score=0.510 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=31, p=1;, score=0.527 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=31, p=1;, score=0.523 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=31, p=1;, score=0.537 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=31, p=1;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=31, p=2;, score=0.513 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=31, p=2;, score=0.526 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=31, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=31, p=2;, score=0.538 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=31, p=2;, score=0.556 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=32, p=1;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=32, p=1;, score=0.527 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=32, p=1;, score=0.523 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=32, p=1;, score=0.535 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=32, p=1;, score=0.547 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=32, p=2;, score=0.510 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=32, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=32, p=2;, score=0.526 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=32, p=2;, score=0.537 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=32, p=2;, score=0.554 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=33, p=1;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=33, p=1;, score=0.525 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=33, p=1;, score=0.520 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=33, p=1;, score=0.535 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=33, p=1;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=33, p=2;, score=0.509 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=33, p=2;, score=0.523 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=33, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=33, p=2;, score=0.536 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=33, p=2;, score=0.552 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=34, p=1;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=34, p=1;, score=0.527 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/5] END ...............n_neighbors=34, p=1;, score=0.519 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=34, p=1;, score=0.536 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=34, p=1;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=34, p=2;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=34, p=2;, score=0.523 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=34, p=2;, score=0.523 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=34, p=2;, score=0.537 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=34, p=2;, score=0.552 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=35, p=1;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=35, p=1;, score=0.526 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=35, p=1;, score=0.517 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=35, p=1;, score=0.535 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=35, p=1;, score=0.547 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=35, p=2;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=35, p=2;, score=0.522 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=35, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=35, p=2;, score=0.535 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=35, p=2;, score=0.554 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=36, p=1;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=36, p=1;, score=0.524 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=36, p=1;, score=0.517 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=36, p=1;, score=0.533 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=36, p=1;, score=0.546 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=36, p=2;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=36, p=2;, score=0.521 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=36, p=2;, score=0.522 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=36, p=2;, score=0.533 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=36, p=2;, score=0.554 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=37, p=1;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=37, p=1;, score=0.523 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=37, p=1;, score=0.518 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=37, p=1;, score=0.533 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=37, p=1;, score=0.546 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=37, p=2;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=37, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=37, p=2;, score=0.524 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=37, p=2;, score=0.532 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=37, p=2;, score=0.552 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=38, p=1;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=38, p=1;, score=0.521 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=38, p=1;, score=0.518 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=38, p=1;, score=0.530 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=38, p=1;, score=0.545 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=38, p=2;, score=0.510 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=38, p=2;, score=0.522 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=38, p=2;, score=0.522 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=38, p=2;, score=0.532 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=38, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=39, p=1;, score=0.502 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=39, p=1;, score=0.520 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=39, p=1;, score=0.516 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=39, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=39, p=1;, score=0.544 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=39, p=2;, score=0.508 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=39, p=2;, score=0.520 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=39, p=2;, score=0.520 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=39, p=2;, score=0.532 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=39, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=40, p=1;, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=40, p=1;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=40, p=1;, score=0.515 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=40, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=40, p=1;, score=0.544 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=40, p=2;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=40, p=2;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=40, p=2;, score=0.517 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=40, p=2;, score=0.532 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=40, p=2;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=41, p=1;, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=41, p=1;, score=0.518 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=41, p=1;, score=0.515 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=41, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=41, p=1;, score=0.544 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=41, p=2;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=41, p=2;, score=0.519 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=41, p=2;, score=0.515 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=41, p=2;, score=0.533 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=41, p=2;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=42, p=1;, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=42, p=1;, score=0.517 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=42, p=1;, score=0.515 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=42, p=1;, score=0.526 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=42, p=1;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=42, p=2;, score=0.507 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=42, p=2;, score=0.518 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=42, p=2;, score=0.516 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=42, p=2;, score=0.531 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=42, p=2;, score=0.549 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=43, p=1;, score=0.502 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=43, p=1;, score=0.516 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=43, p=1;, score=0.513 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=43, p=1;, score=0.528 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=43, p=1;, score=0.543 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=43, p=2;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=43, p=2;, score=0.518 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=43, p=2;, score=0.515 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=43, p=2;, score=0.529 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=43, p=2;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=44, p=1;, score=0.502 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=44, p=1;, score=0.514 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=44, p=1;, score=0.512 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=44, p=1;, score=0.526 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=44, p=1;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=44, p=2;, score=0.506 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=44, p=2;, score=0.517 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=44, p=2;, score=0.513 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=44, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=44, p=2;, score=0.548 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=45, p=1;, score=0.502 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=45, p=1;, score=0.512 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=45, p=1;, score=0.511 total time=   0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 4/5] END ...............n_neighbors=45, p=1;, score=0.527 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=45, p=1;, score=0.543 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=45, p=2;, score=0.505 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=45, p=2;, score=0.518 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=45, p=2;, score=0.513 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=45, p=2;, score=0.529 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=45, p=2;, score=0.546 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=46, p=1;, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=46, p=1;, score=0.509 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=46, p=1;, score=0.509 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=46, p=1;, score=0.525 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=46, p=1;, score=0.541 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=46, p=2;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=46, p=2;, score=0.517 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=46, p=2;, score=0.511 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=46, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=46, p=2;, score=0.546 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=47, p=1;, score=0.500 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=47, p=1;, score=0.509 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=47, p=1;, score=0.508 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=47, p=1;, score=0.525 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=47, p=1;, score=0.540 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=47, p=2;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=47, p=2;, score=0.516 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=47, p=2;, score=0.510 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=47, p=2;, score=0.530 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=47, p=2;, score=0.544 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=48, p=1;, score=0.499 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=48, p=1;, score=0.510 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=48, p=1;, score=0.508 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=48, p=1;, score=0.524 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=48, p=1;, score=0.539 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=48, p=2;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=48, p=2;, score=0.515 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=48, p=2;, score=0.510 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=48, p=2;, score=0.531 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=48, p=2;, score=0.542 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=49, p=1;, score=0.501 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=49, p=1;, score=0.509 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=49, p=1;, score=0.507 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=49, p=1;, score=0.524 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=49, p=1;, score=0.538 total time=   0.0s\n",
      "[CV 1/5] END ...............n_neighbors=49, p=2;, score=0.504 total time=   0.0s\n",
      "[CV 2/5] END ...............n_neighbors=49, p=2;, score=0.515 total time=   0.0s\n",
      "[CV 3/5] END ...............n_neighbors=49, p=2;, score=0.509 total time=   0.0s\n",
      "[CV 4/5] END ...............n_neighbors=49, p=2;, score=0.531 total time=   0.0s\n",
      "[CV 5/5] END ...............n_neighbors=49, p=2;, score=0.542 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsRegressor(),\n",
       "             param_grid={'n_neighbors': range(1, 50), 'p': [1, 2]}, verbose=3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "params_grid = {\"n_neighbors\": range(1, 50), \"p\": [1,2]}\n",
    "grid = GridSearchCV(KNeighborsRegressor(), params_grid,refit=True,verbose=3)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 19, 'p': 2}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE:  2.1880618850148883\n"
     ]
    }
   ],
   "source": [
    "test_preds_grid = grid.predict(X_test)\n",
    "test_mse = mean_squared_error(y_test, test_preds_grid)\n",
    "\n",
    "print('Test RMSE: ', np.sqrt(test_mse))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
