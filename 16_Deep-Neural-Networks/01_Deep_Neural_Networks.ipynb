{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yin-penghang/AMAT593/blob/main/16_Deep-Neural-Networks/01_Deep_Neural_Networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_8M_4Cor4H2s"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yin-penghang/AMAT593/blob/main/16_Deep-Neural-Networks/01_Deep%20Neural%20Networks.ipynb\"><img align=\"left\" src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open in Colab\" title=\"Open and Execute in Google Colaboratory\"></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uK-UfbhA0pK5"
      },
      "source": [
        "# Deep Neural Networks\n",
        "\n",
        "The code for network training should be executed within Google's [Colab Notebook](https://colab.research.google.com/github/yin-penghang/AMAT593/blob/main/16_Deep-Neural-Networks/01_Deep%20Neural%20Networks.ipynb) using GPU.\n",
        "\n",
        "## Basics \n",
        "\n",
        "In deep learning, we take deep neural networks as the model architecture. The word \"deep\" in \"deep learning\" refers to the number of layers through which the data is transformed. Deep learning architectures such as convolutional neural networks, recurrent neural networks and transformers have been applied to fields including computer vision, speech recognition, sentiment analysis, machine translation, bioinformatics, drug design, medical image analysis, material inspection and board game programs, where they have produced results comparable to and in some cases surpassing human expert performance.\n",
        "\n",
        "### Why GPU For Deep Learning \n",
        "\n",
        "A CPU in general completes its task in a **sequential** manner, whereas a GPU is the able to process a large number of simple calculations **in parallel**, which makes it very suitable for computing matrix multiplications and convolutions in deep learning.\n",
        "\n",
        "### Deep Learning Libraries and Platforms\n",
        "\n",
        "There are a number of open-source deep learning libraries and platforms available. Among them, [PyTorch](https://pytorch.org/) by Facebook and [TensorFlow](https://www.tensorflow.org/) by Google are the most popular for academic and research activities.\n",
        "\n",
        "We will use TensorFlow for lecturing. We will also need **Keras**, which is a high-level neural network library that runs on top of TensorFlow. \n",
        "\n",
        "You need to install Python dependecies ``tensorflow`` and ``keras`` for deep learning:\n",
        "- ``pip install tensorflow``\n",
        "- ``pip install keras``\n",
        "\n",
        "Building neural network models is like playing Lego, deep learning libraries provide the modules of different types of layers — Lego blocks  — to construct network architectures in a flexible way. They also include various convenient utility functions such as metrics as well as optimizers, making deep learning easy to train and deploy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "geM8VqIH3N2F"
      },
      "source": [
        "## Enabling GPU in Colab Notebook\n",
        "\n",
        "GPUs can process data several orders of magnitude faster than a CPU due to **massive parallelism**, although GPUs are not as versatile as CPUs. \n",
        "\n",
        "However, setting up a GPU so that it is ready for deep learning can be painful, as it requires the installation of several open-source softwares whose respective versions need to be compatible. **We can skip the software requirement if using GPU-enbaled Colab Notebook.**\n",
        "\n",
        "First, you'll need to enable GPU for the notebook:\n",
        "\n",
        "- Navigate to Edit→Notebook Settings\n",
        "- select GPU from the Hardware Accelerator drop-down\n",
        "\n",
        "Next, we'll confirm that we can connect to the GPU with tensorflow:"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import timeit"
      ],
      "metadata": {
        "id": "6NsnSvoDIqXj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Rdr6gTC1ctW",
        "outputId": "7654df09-ad69-4de7-b02e-e86045607346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  raise SystemError('GPU device not found')\n",
        "print('Found GPU at: {}'.format(device_name))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTQlUqK87B9j"
      },
      "source": [
        "### Observe TensorFlow speedup on GPU relative to CPU\n",
        "\n",
        "This example constructs a typical convolutional layer over a\n",
        "random image and manually places the resulting ops on either the CPU or the GPU to compare execution speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-8xvcQHY7RQ-",
        "outputId": "7d9d6aba-ce57-4a68-e4a6-528abccd56c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images (batch size x height x width x channel).\n",
            "\n",
            " CPU time (s):\n",
            "4.381552384000031\n",
            "\n",
            " GPU time (s):\n",
            "0.09837672099996553\n",
            "\n",
            " GPU speedup over CPU: 44x\n"
          ]
        }
      ],
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name != '/device:GPU:0':\n",
        "  print(\n",
        "      '\\n\\nThis error most likely means that this notebook is not '\n",
        "      'configured to use a GPU.  Change this in Notebook Settings via the '\n",
        "      'command palette (cmd/ctrl-shift-P) or the Edit menu.\\n\\n')\n",
        "  raise SystemError('GPU device not found')\n",
        "\n",
        "def cpu():\n",
        "  with tf.device('/cpu:0'):\n",
        "    random_image_cpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_cpu = tf.keras.layers.Conv2D(32, 7)(random_image_cpu)\n",
        "    return tf.math.reduce_sum(net_cpu)\n",
        "\n",
        "def gpu():\n",
        "  with tf.device('/device:GPU:0'):\n",
        "    random_image_gpu = tf.random.normal((100, 100, 100, 3))\n",
        "    net_gpu = tf.keras.layers.Conv2D(32, 7)(random_image_gpu)\n",
        "    return tf.math.reduce_sum(net_gpu)\n",
        "  \n",
        "# We run each op once to warm up\n",
        "cpu()\n",
        "gpu()\n",
        "\n",
        "# Run the op several times.\n",
        "print('Time (s) to convolve 32x7x7x3 filter over random 100x100x100x3 images '\n",
        "      '(batch size x height x width x channel).')\n",
        "print('\\n CPU time (s):')\n",
        "cpu_time = timeit.timeit('cpu()', number=10, setup=\"from __main__ import cpu\")\n",
        "print(cpu_time)\n",
        "print('\\n GPU time (s):')\n",
        "gpu_time = timeit.timeit('gpu()', number=10, setup=\"from __main__ import gpu\")\n",
        "print(gpu_time)\n",
        "print('\\n GPU speedup over CPU: {}x'.format(int(cpu_time/gpu_time)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8E7UOzPvJc9"
      },
      "source": [
        "## Deep Learning with Local GPU\n",
        "\n",
        "There are limitations of using Colab's GPU for deep learning. For example, the GPU allocation per non-paid user is restricted to maximum 12 hours at a time. The next time you can use it will probably be after 12 hours or once another user has given up GPU ability. \n",
        "\n",
        "If you have a bare machine with an **NVIDIA** GPU card available, you may want to set up your own computers to be deep learning ready. The main reason that you need an NVIDIA GPU is because of [CUDA](https://en.wikipedia.org/wiki/CUDA). CUDA is a proprietary programming framework developed by NVIDIA that facilitates massive parallelization of computing tasks using the cores in an NVIDIA GPU. You'll also need to install [cuDNN](https://developer.nvidia.com/cudnn), a GPU-accelerated library of primitives for deep neural networks built using CUDA.\n",
        "\n",
        "Please check out [this article](https://spltech.co.uk/building-my-first-pc-for-deep-learning/) for details. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gKKnoFPL4IAr"
      },
      "source": [
        "## MNIST Data preparation\n",
        "\n",
        "Load MNIST dataset from Keras and Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0FigdiN2I_n"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import mnist\n",
        "from keras.utils import np_utils\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uphD4Cr34IAr"
      },
      "source": [
        "load (download if needed) the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uG9yc0x62_5g",
        "outputId": "be15edee-8949-4d97-8bfb-060412698ef2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 1s 0us/step\n"
          ]
        }
      ],
      "source": [
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dM1WDqQPBz1E",
        "outputId": "fe177ad1-15dc-4a82-a53b-09858fff8263"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 28, 28)\n",
            "(60000,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "print(X_train.shape), print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuzoiVEoIIqM",
        "outputId": "497b9943-7144-45d1-85e9-0876b1c745f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "print(X_test.shape), print(y_test.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtCnUiAnTQHk"
      },
      "source": [
        "Plot 4 images as gray scale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268
        },
        "id": "oiz67TOB3ABV",
        "outputId": "99bbabd8-4ab4-4d77-8033-1e77cdd690e9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "for i in range(4):\n",
        "    plt.subplot(2,2,i+1)\n",
        "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQ94rPQX4IAu"
      },
      "source": [
        "## Warmup Example 1 : Logistic Regression\n",
        "\n",
        "To use logistic regression model, we will need to first flatten out the image samples into vectors. \n",
        "\n",
        "<img src='https://github.com/yin-penghang/AMAT593/blob/main/figs/16_MNIST_LR.png?raw=1' width = '800'>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AV99b76kFAEG"
      },
      "source": [
        "Flatten 28x28 images to a 784 vector for each image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hKJXlCni31hm"
      },
      "outputs": [],
      "source": [
        "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
        "X_train = X_train.reshape((X_train.shape[0], num_pixels)).astype('float32')\n",
        "X_test = X_test.reshape((X_test.shape[0], num_pixels)).astype('float32')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rjsKUQixE6In"
      },
      "source": [
        "Normalize inputs from 0-255 to 0-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iWYubs7G31Uc"
      },
      "outputs": [],
      "source": [
        "X_tr = X_train / 255\n",
        "X_te = X_test / 255"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tw9_K3xQFHDN"
      },
      "source": [
        "Encode one-hot labels which are 10-D vectors, e.g., \n",
        "- digit 0 -> label (1,0,0,...,0)\n",
        "- digit 1 -> label (0,1,0,...,0)\n",
        "- digit 2 -> label (0,0,1,...,0)\n",
        "- ...\n",
        "- digit 9 -> label (0,0,0,...,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "COH8ejau4qm8",
        "outputId": "0a9f65ca-23bb-4aa4-b8d5-e80dfce059aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(60000, 10)\n"
          ]
        }
      ],
      "source": [
        "y_tr = np_utils.to_categorical(y_train,10)\n",
        "y_te = np_utils.to_categorical(y_test,10)\n",
        "num_classes = y_te.shape[1]\n",
        "\n",
        "print(y_tr.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RCkF0rag4IAv"
      },
      "source": [
        "### Implementation\n",
        "\n",
        "Create a new instance of a model object using the Keras **`Sequential` API**.\n",
        "The core idea of `Sequential` API is simply arranging the Keras layers in a sequential order. Most of the neural networks has layers in sequential order and the data flows from one layer to another layer in the given order until the data finally reaches the output layer.\n",
        "\n",
        "Specifically, we add a dense layer (fully-connected layer), followed by softmax function that normalizes outputs into probabilities which sum to one. We use ``categorical_crossentropy`` cross-entropy loss and ``adam`` optimization algorithm. \n",
        "\n",
        "Another popular way to create models in Keras is the **functional API** which is more flexible than `Sequential` API. The functional API can handle models with non-linear topology, shared layers, and multiple inputs or outputs.\n",
        "\n",
        "\n",
        "[Adam](https://arxiv.org/pdf/1412.6980.pdf) is a SGD variant with adaptive learning rate for each individual parameter. It is an viable alternative to Nesterov accelerated SGD and has gained much popularity in deep learning, because it requires only **minimum tuning of learning rate and other algorithmic hyper-parameters**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ToZgrGOn31pd"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use `Sequential` API: "
      ],
      "metadata": {
        "id": "p3ME-cl6-nvx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZKC9pJiw4IAv"
      },
      "outputs": [],
      "source": [
        "def logit_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  # Fully-connected Layer with Softmax output\n",
        "  model.add(Dense(units = num_classes, activation='softmax'))\n",
        "  # Compile model with corss entropy loss and Adam optimizer\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we use the functional API, it will be like:"
      ],
      "metadata": {
        "id": "d5QCwZCb_0zM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Model\n",
        "from keras.layers import Input"
      ],
      "metadata": {
        "id": "DPHvcBiWBICK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def logit_model():\n",
        "  # Input layer\n",
        "  input = Input(shape = (num_pixels,))\n",
        "  # Fully-connected Layer with Softmax output\n",
        "  output = Dense(units = num_classes, activation='softmax')(input)\n",
        "\n",
        "  model = Model(inputs = input, outputs = output)\n",
        "  # Compile model with corss entropy loss and Adam optimizer\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='Adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "metadata": {
        "id": "wRcMGM3KAHMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16iSRLNIxzP5"
      },
      "source": [
        "### Model Validation:\n",
        "\n",
        "* `ModelCheckpoint` callback will ensure that the weights of model with the best validation accuracy is saved for the run for us to use later.  \n",
        "* use `EarlyStopping` callback to interrupt training when the validation accuracy\n",
        "is not improving for `patience=7` consecutive epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UM5c_6vFvygB"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import EarlyStopping, ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7iUx4qXvJdD"
      },
      "outputs": [],
      "source": [
        "path_checkpoint = \"logit_checkpoint.h5\"\n",
        "es_callback = EarlyStopping(monitor=\"val_accuracy\", patience=7)\n",
        "\n",
        "modelckpt_callback = ModelCheckpoint(\n",
        "    monitor=\"val_accuracy\",\n",
        "    filepath=path_checkpoint,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9R6nWAC44IAw",
        "outputId": "ba299ca8-235c-4100-8760-95c85a83d0e6",
        "scrolled": false
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.90380, saving model to logit_checkpoint.h5\n",
            "600/600 - 4s - loss: 0.6260 - accuracy: 0.8456 - val_loss: 0.3621 - val_accuracy: 0.9038 - 4s/epoch - 6ms/step\n",
            "Epoch 2/40\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.90380 to 0.91440, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.3453 - accuracy: 0.9058 - val_loss: 0.3098 - val_accuracy: 0.9144 - 1s/epoch - 2ms/step\n",
            "Epoch 3/40\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.91440 to 0.91910, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.3091 - accuracy: 0.9147 - val_loss: 0.2883 - val_accuracy: 0.9191 - 1s/epoch - 2ms/step\n",
            "Epoch 4/40\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.91910 to 0.92220, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2924 - accuracy: 0.9186 - val_loss: 0.2813 - val_accuracy: 0.9222 - 1s/epoch - 2ms/step\n",
            "Epoch 5/40\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.92220 to 0.92370, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2817 - accuracy: 0.9215 - val_loss: 0.2746 - val_accuracy: 0.9237 - 1s/epoch - 2ms/step\n",
            "Epoch 6/40\n",
            "\n",
            "Epoch 6: val_accuracy improved from 0.92370 to 0.92460, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2747 - accuracy: 0.9234 - val_loss: 0.2711 - val_accuracy: 0.9246 - 1s/epoch - 2ms/step\n",
            "Epoch 7/40\n",
            "\n",
            "Epoch 7: val_accuracy improved from 0.92460 to 0.92540, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2694 - accuracy: 0.9250 - val_loss: 0.2698 - val_accuracy: 0.9254 - 1s/epoch - 2ms/step\n",
            "Epoch 8/40\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.92540\n",
            "600/600 - 2s - loss: 0.2653 - accuracy: 0.9267 - val_loss: 0.2678 - val_accuracy: 0.9254 - 2s/epoch - 3ms/step\n",
            "Epoch 9/40\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.92540\n",
            "600/600 - 2s - loss: 0.2618 - accuracy: 0.9273 - val_loss: 0.2687 - val_accuracy: 0.9253 - 2s/epoch - 3ms/step\n",
            "Epoch 10/40\n",
            "\n",
            "Epoch 10: val_accuracy improved from 0.92540 to 0.92560, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2590 - accuracy: 0.9282 - val_loss: 0.2676 - val_accuracy: 0.9256 - 1s/epoch - 2ms/step\n",
            "Epoch 11/40\n",
            "\n",
            "Epoch 11: val_accuracy improved from 0.92560 to 0.92610, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2568 - accuracy: 0.9292 - val_loss: 0.2651 - val_accuracy: 0.9261 - 1s/epoch - 2ms/step\n",
            "Epoch 12/40\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.92610\n",
            "600/600 - 2s - loss: 0.2547 - accuracy: 0.9294 - val_loss: 0.2657 - val_accuracy: 0.9256 - 2s/epoch - 3ms/step\n",
            "Epoch 13/40\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.92610\n",
            "600/600 - 1s - loss: 0.2531 - accuracy: 0.9300 - val_loss: 0.2686 - val_accuracy: 0.9261 - 1s/epoch - 2ms/step\n",
            "Epoch 14/40\n",
            "\n",
            "Epoch 14: val_accuracy improved from 0.92610 to 0.92720, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2514 - accuracy: 0.9299 - val_loss: 0.2636 - val_accuracy: 0.9272 - 1s/epoch - 2ms/step\n",
            "Epoch 15/40\n",
            "\n",
            "Epoch 15: val_accuracy improved from 0.92720 to 0.92740, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2498 - accuracy: 0.9311 - val_loss: 0.2628 - val_accuracy: 0.9274 - 1s/epoch - 2ms/step\n",
            "Epoch 16/40\n",
            "\n",
            "Epoch 16: val_accuracy improved from 0.92740 to 0.92830, saving model to logit_checkpoint.h5\n",
            "600/600 - 1s - loss: 0.2485 - accuracy: 0.9312 - val_loss: 0.2615 - val_accuracy: 0.9283 - 1s/epoch - 2ms/step\n",
            "Epoch 17/40\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.92830\n",
            "600/600 - 2s - loss: 0.2472 - accuracy: 0.9321 - val_loss: 0.2638 - val_accuracy: 0.9282 - 2s/epoch - 3ms/step\n",
            "Epoch 18/40\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.92830\n",
            "600/600 - 1s - loss: 0.2461 - accuracy: 0.9324 - val_loss: 0.2639 - val_accuracy: 0.9273 - 1s/epoch - 2ms/step\n",
            "Epoch 19/40\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.92830\n",
            "600/600 - 1s - loss: 0.2451 - accuracy: 0.9325 - val_loss: 0.2624 - val_accuracy: 0.9272 - 1s/epoch - 2ms/step\n",
            "Epoch 20/40\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.92830\n",
            "600/600 - 1s - loss: 0.2443 - accuracy: 0.9326 - val_loss: 0.2645 - val_accuracy: 0.9272 - 1s/epoch - 2ms/step\n",
            "Epoch 21/40\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.92830\n",
            "600/600 - 1s - loss: 0.2432 - accuracy: 0.9334 - val_loss: 0.2614 - val_accuracy: 0.9272 - 1s/epoch - 2ms/step\n",
            "Epoch 22/40\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.92830\n",
            "600/600 - 2s - loss: 0.2426 - accuracy: 0.9333 - val_loss: 0.2636 - val_accuracy: 0.9274 - 2s/epoch - 3ms/step\n",
            "Epoch 23/40\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.92830\n",
            "600/600 - 1s - loss: 0.2414 - accuracy: 0.9334 - val_loss: 0.2645 - val_accuracy: 0.9269 - 1s/epoch - 2ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8a0c3f8370>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "# build the model\n",
        "model = logit_model()\n",
        "# Fit the model\n",
        "model.fit(X_tr, y_tr, validation_data=(X_te, y_te), \n",
        "          epochs=40, batch_size=100, \n",
        "          callbacks=[es_callback, modelckpt_callback], \n",
        "          verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ONFjMgyr5Da"
      },
      "source": [
        "### Save and Load the Trained Model\n",
        "\n",
        "It is very convenient to save the trained neural network model. You can load it whenever needed for prediction.\n",
        "\n",
        "The model consists of multiple components:\n",
        "\n",
        "* the architecture, or configuration, which specifies what layers the model contain, and how they're connected.\n",
        "\n",
        "* a set of weights values (the \"state of the model\").\n",
        "\n",
        "* an optimizer (defined by compiling the model).\n",
        "\n",
        "* a set of losses and metrics (defined by compiling the model or calling add_loss() or add_metric()).\n",
        "\n",
        "There are two formats you can use to save an entire model to disk: the TensorFlow **SavedModel** format, and the older Keras **H5 format**. **SavedModel** format is the default when you use ``model.save()``."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2o72DYEydjP"
      },
      "source": [
        "Chekc the validation accuracy of the checkpointed model by loading the saved weights."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ma2nrf44943T"
      },
      "outputs": [],
      "source": [
        "model.save('logit')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYW-6f46wOpD",
        "outputId": "c697a6fb-7591-4f74-99b7-c0541cf06cc9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Best validation accuracy: 92.69%\n"
          ]
        }
      ],
      "source": [
        "# load the saved weights \n",
        "model.load_weights('logit')\n",
        "scores = model.evaluate(X_te, y_te, verbose=0)\n",
        "print(\"\\n Best validation accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Plr5jmgE4IAw"
      },
      "source": [
        "**We can check the total number of trainable parameters in the model**:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NE1qBIIp4IAw",
        "outputId": "4621b057-3480-483d-b85b-ff4f8cd81007"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_6\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_8 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jQOBaKW673rE"
      },
      "source": [
        "## Warmup Example 2 : Two-Layer Networks\n",
        "\n",
        "We can view logistic regression model as a **one-dense-layer network** with 784x10 weight matrix. Next, we aim to improve the prediction accuracy, adding one more dense layer with a nonlinear activation layer (applied **entry-wise**), so-called **rectified linear units (ReLU)** \n",
        "\n",
        "$$\n",
        "\\sigma(x) = \\max(x,0)\n",
        "$$ \n",
        "\n",
        "to increase the model capacity/complexity. \n",
        "\n",
        "<img src='https://github.com/yin-penghang/AMAT593/blob/main/figs/16_ReLU.png?raw=1'>\n",
        "\n",
        "However, adding dense layers will result in **tremendous growth of the number of model parameters.** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L45G6Jg18_3g"
      },
      "source": [
        "**Define Two-Layer Model**\n",
        "\n",
        "Create a new instance of a model object using sequential model API. Then add two Dense linear layers, one ReLU activation layer, and Softmax output layer to the architecture. Finally, compile the model with the ``categorical_crossentropy`` loss function and ``adam`` optimization algorithm. When compiling the model, add ``metrics=[‘accuracy’]`` to calculate the accuracy of the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zZHo_tiR41t3"
      },
      "outputs": [],
      "source": [
        "def two_layer_model():\n",
        "  # create model\n",
        "  model = Sequential()\n",
        "  # Fully-connected Layer with ReLU activation\n",
        "  model.add(Dense(units = num_pixels, activation='relu'))\n",
        "  # Fully-connected Layer with Softmax output\n",
        "  model.add(Dense(units = num_classes, activation='softmax'))\n",
        "  # Compile model with corss entropy loss and Adam optimizer\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1h_y2H0r1wiN"
      },
      "source": [
        "Set up the callbacks for checkpoint and early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-AjzQDu5ztPE"
      },
      "outputs": [],
      "source": [
        "path_checkpoint = \"2layer_checkpoint.h5\"\n",
        "es_callback = EarlyStopping(monitor=\"val_accuracy\", patience=7)\n",
        "\n",
        "modelckpt_callback = ModelCheckpoint(\n",
        "    monitor=\"val_accuracy\",\n",
        "    filepath=path_checkpoint,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYRIJguJGb5s"
      },
      "source": [
        "Build, train, and evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZVOGXIzl46FC",
        "outputId": "2ab5e7df-2eab-4c60-8ba7-b89eb4c904da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "600/600 - 2s - loss: 0.2308 - accuracy: 0.9334 - val_loss: 0.1094 - val_accuracy: 0.9672\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.96720, saving model to 2layer_checkpoint.h5\n",
            "Epoch 2/50\n",
            "600/600 - 1s - loss: 0.0900 - accuracy: 0.9733 - val_loss: 0.0834 - val_accuracy: 0.9738\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.96720 to 0.97380, saving model to 2layer_checkpoint.h5\n",
            "Epoch 3/50\n",
            "600/600 - 1s - loss: 0.0568 - accuracy: 0.9826 - val_loss: 0.0679 - val_accuracy: 0.9782\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.97380 to 0.97820, saving model to 2layer_checkpoint.h5\n",
            "Epoch 4/50\n",
            "600/600 - 2s - loss: 0.0386 - accuracy: 0.9887 - val_loss: 0.0650 - val_accuracy: 0.9787\n",
            "\n",
            "Epoch 00004: val_accuracy improved from 0.97820 to 0.97870, saving model to 2layer_checkpoint.h5\n",
            "Epoch 5/50\n",
            "600/600 - 2s - loss: 0.0294 - accuracy: 0.9913 - val_loss: 0.0586 - val_accuracy: 0.9825\n",
            "\n",
            "Epoch 00005: val_accuracy improved from 0.97870 to 0.98250, saving model to 2layer_checkpoint.h5\n",
            "Epoch 6/50\n",
            "600/600 - 1s - loss: 0.0200 - accuracy: 0.9942 - val_loss: 0.0584 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.98250\n",
            "Epoch 7/50\n",
            "600/600 - 1s - loss: 0.0154 - accuracy: 0.9955 - val_loss: 0.0646 - val_accuracy: 0.9795\n",
            "\n",
            "Epoch 00007: val_accuracy did not improve from 0.98250\n",
            "Epoch 8/50\n",
            "600/600 - 1s - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0766 - val_accuracy: 0.9777\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.98250\n",
            "Epoch 9/50\n",
            "600/600 - 1s - loss: 0.0099 - accuracy: 0.9969 - val_loss: 0.0690 - val_accuracy: 0.9808\n",
            "\n",
            "Epoch 00009: val_accuracy did not improve from 0.98250\n",
            "Epoch 10/50\n",
            "600/600 - 2s - loss: 0.0082 - accuracy: 0.9978 - val_loss: 0.0702 - val_accuracy: 0.9811\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.98250\n",
            "Epoch 11/50\n",
            "600/600 - 1s - loss: 0.0059 - accuracy: 0.9985 - val_loss: 0.0649 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.98250 to 0.98280, saving model to 2layer_checkpoint.h5\n",
            "Epoch 12/50\n",
            "600/600 - 2s - loss: 0.0084 - accuracy: 0.9973 - val_loss: 0.0740 - val_accuracy: 0.9814\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.98280\n",
            "Epoch 13/50\n",
            "600/600 - 1s - loss: 0.0064 - accuracy: 0.9981 - val_loss: 0.0745 - val_accuracy: 0.9822\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.98280\n",
            "Epoch 14/50\n",
            "600/600 - 1s - loss: 0.0083 - accuracy: 0.9976 - val_loss: 0.0690 - val_accuracy: 0.9831\n",
            "\n",
            "Epoch 00014: val_accuracy improved from 0.98280 to 0.98310, saving model to 2layer_checkpoint.h5\n",
            "Epoch 15/50\n",
            "600/600 - 1s - loss: 0.0037 - accuracy: 0.9990 - val_loss: 0.0708 - val_accuracy: 0.9841\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.98310 to 0.98410, saving model to 2layer_checkpoint.h5\n",
            "Epoch 16/50\n",
            "600/600 - 2s - loss: 0.0048 - accuracy: 0.9986 - val_loss: 0.1006 - val_accuracy: 0.9772\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.98410\n",
            "Epoch 17/50\n",
            "600/600 - 2s - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0762 - val_accuracy: 0.9828\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.98410\n",
            "Epoch 18/50\n",
            "600/600 - 2s - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0782 - val_accuracy: 0.9834\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.98410\n",
            "Epoch 19/50\n",
            "600/600 - 1s - loss: 0.0030 - accuracy: 0.9992 - val_loss: 0.0823 - val_accuracy: 0.9823\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.98410\n",
            "Epoch 20/50\n",
            "600/600 - 2s - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0735 - val_accuracy: 0.9839\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.98410\n",
            "Epoch 21/50\n",
            "600/600 - 2s - loss: 8.6521e-04 - accuracy: 0.9999 - val_loss: 0.0737 - val_accuracy: 0.9843\n",
            "\n",
            "Epoch 00021: val_accuracy improved from 0.98410 to 0.98430, saving model to 2layer_checkpoint.h5\n",
            "Epoch 22/50\n",
            "600/600 - 1s - loss: 2.7830e-04 - accuracy: 1.0000 - val_loss: 0.0714 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00022: val_accuracy improved from 0.98430 to 0.98490, saving model to 2layer_checkpoint.h5\n",
            "Epoch 23/50\n",
            "600/600 - 2s - loss: 9.8290e-05 - accuracy: 1.0000 - val_loss: 0.0732 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00023: val_accuracy did not improve from 0.98490\n",
            "Epoch 24/50\n",
            "600/600 - 1s - loss: 6.1541e-05 - accuracy: 1.0000 - val_loss: 0.0736 - val_accuracy: 0.9848\n",
            "\n",
            "Epoch 00024: val_accuracy did not improve from 0.98490\n",
            "Epoch 25/50\n",
            "600/600 - 2s - loss: 4.8387e-05 - accuracy: 1.0000 - val_loss: 0.0745 - val_accuracy: 0.9848\n",
            "\n",
            "Epoch 00025: val_accuracy did not improve from 0.98490\n",
            "Epoch 26/50\n",
            "600/600 - 1s - loss: 3.8969e-05 - accuracy: 1.0000 - val_loss: 0.0756 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00026: val_accuracy did not improve from 0.98490\n",
            "Epoch 27/50\n",
            "600/600 - 2s - loss: 3.1995e-05 - accuracy: 1.0000 - val_loss: 0.0766 - val_accuracy: 0.9848\n",
            "\n",
            "Epoch 00027: val_accuracy did not improve from 0.98490\n",
            "Epoch 28/50\n",
            "600/600 - 2s - loss: 2.6725e-05 - accuracy: 1.0000 - val_loss: 0.0772 - val_accuracy: 0.9849\n",
            "\n",
            "Epoch 00028: val_accuracy did not improve from 0.98490\n",
            "Epoch 29/50\n",
            "600/600 - 2s - loss: 2.3194e-05 - accuracy: 1.0000 - val_loss: 0.0781 - val_accuracy: 0.9852\n",
            "\n",
            "Epoch 00029: val_accuracy improved from 0.98490 to 0.98520, saving model to 2layer_checkpoint.h5\n",
            "Epoch 30/50\n",
            "600/600 - 1s - loss: 0.0157 - accuracy: 0.9960 - val_loss: 0.1122 - val_accuracy: 0.9781\n",
            "\n",
            "Epoch 00030: val_accuracy did not improve from 0.98520\n",
            "Epoch 31/50\n",
            "600/600 - 1s - loss: 0.0104 - accuracy: 0.9966 - val_loss: 0.0808 - val_accuracy: 0.9830\n",
            "\n",
            "Epoch 00031: val_accuracy did not improve from 0.98520\n",
            "Epoch 32/50\n",
            "600/600 - 1s - loss: 0.0015 - accuracy: 0.9996 - val_loss: 0.0779 - val_accuracy: 0.9837\n",
            "\n",
            "Epoch 00032: val_accuracy did not improve from 0.98520\n",
            "Epoch 33/50\n",
            "600/600 - 2s - loss: 3.6269e-04 - accuracy: 1.0000 - val_loss: 0.0799 - val_accuracy: 0.9842\n",
            "\n",
            "Epoch 00033: val_accuracy did not improve from 0.98520\n",
            "Epoch 34/50\n",
            "600/600 - 2s - loss: 1.2146e-04 - accuracy: 1.0000 - val_loss: 0.0783 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00034: val_accuracy did not improve from 0.98520\n",
            "Epoch 35/50\n",
            "600/600 - 1s - loss: 7.1750e-05 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9846\n",
            "\n",
            "Epoch 00035: val_accuracy did not improve from 0.98520\n",
            "Epoch 36/50\n",
            "600/600 - 2s - loss: 4.6166e-05 - accuracy: 1.0000 - val_loss: 0.0787 - val_accuracy: 0.9847\n",
            "\n",
            "Epoch 00036: val_accuracy did not improve from 0.98520\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7feb6009ee50>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# build the model\n",
        "model = two_layer_model()\n",
        "# Fit the model\n",
        "# Fit the model\n",
        "model.fit(X_tr, y_tr, validation_data=(X_te, y_te), \n",
        "          epochs=50, batch_size=100, \n",
        "          callbacks=[es_callback, modelckpt_callback], \n",
        "          verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQR_bu7U943V"
      },
      "source": [
        "**Load the model directly from checkpoint:**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "71F3auwG0B20",
        "outputId": "6ad8a5db-9f5c-4ea0-8618-06b99ecfb9ef"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Best validation accuracy: 98.52%\n"
          ]
        }
      ],
      "source": [
        "# load the saved weights \n",
        "model.load_weights(path_checkpoint)\n",
        "scores = model.evaluate(X_te, y_te, verbose=0)\n",
        "print(\"\\n Best validation accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA-O37s0r5DX"
      },
      "source": [
        "The two-dense-layer network has 623,290 trainable parameters:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aa5fx1-C4IAy",
        "outputId": "32c2d322-ec37-4157-833a-9b23936bcbcd",
        "scrolled": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_1 (Dense)              (None, 784)               615440    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 623,290\n",
            "Trainable params: 623,290\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GZ370z56MOC"
      },
      "source": [
        "## MNIST Classification with LeNet-5\n",
        "\n",
        "LeNet-5 architecture was proposed by [LeCun et al.](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf) in 1998. It has 5 linear layers including 3 convolutional layers and 2 dense layers. \n",
        "\n",
        "\n",
        "<img src = '../figs/16_lenet5.png'>\n",
        "\n",
        "The original LeNet-5 architecture:\n",
        "\n",
        "* pad each images with zeros and increase size to 32x32\n",
        "\n",
        "* convolutional layer $C_1$ with 6 filters of size 5x5, followed by tanh activation layer. **output dimension = 28x28x6**\n",
        "\n",
        "* 2x2 average pooling layer $S_2$ for subsampling. **output dimension = 14x14x6**\n",
        "\n",
        "* convolutional layer $C_3$ with 16 filters of size 6x5x5, followed by tanh activation layer. **output dimension = 10x10x16**\n",
        "\n",
        "* 2x2 average pooling layer $S_4$ for subsampling. **output dimension = 5x5x16**\n",
        "\n",
        "* convolutional layer $C_5$ with 120 filters of size 16x5x5, followed by tanh activation layer. **output dimension = 1x1x120**\n",
        "\n",
        "* flatten out the 120x1x1 tensor into 120-D vector.\n",
        "\n",
        "* dense layer of 84x120 weight matrix.  **output dimension = 84**\n",
        "\n",
        "* dense layer of 10x84 weight matrix.  **output dimension = 10**\n",
        "\n",
        "* softmax layer\n",
        "\n",
        "\n",
        "Convolutional neural networks have the following merits:\n",
        "\n",
        "* Convolutional layers use **weight sharing** and subsampling (known as **pooling**), leading to compact model sizes. \n",
        "\n",
        "* Convolutional neural networks are very good feature extractors. They outperform dense neural networks on conventional image recognition tasks and many other tasks. \n",
        "\n",
        "\n",
        "#### How a convolutional layer works (with kernel_size=(3, 3), strides = 1, padding = 1):\n",
        "\n",
        "<img src = '../figs/16_conv2d.gif'>\n",
        "\n",
        "* Weights (in the kernel) are re-used across the patches, so-called weight **sharing**\n",
        "\n",
        "#### How 2x2 pooling works (with strides = 2): \n",
        "\n",
        "<img src = '../figs/16_maxpool.gif'>\n",
        "\n",
        "* Each dimension is halved.\n",
        "\n",
        "#### Feature maps output from the intermediate layers of LeNet-5 in generating predictions:\n",
        "\n",
        "<img src = '../figs/16_lenet.gif' width = 800>\n",
        "\n",
        "\n",
        "Morden convolutional nerual networks only have one dense layer on the top serving as the linear classifer with all convolutional layers beneath as the feature extractor. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QfnOlMhL0pLJ"
      },
      "source": [
        "Reload the image and reshape images into 4-D array"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oa4yWpu4Bx4D"
      },
      "outputs": [],
      "source": [
        "from keras.utils import np_utils\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "# Set numeric type to float32 from uint8\n",
        "X_train = X_train.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "\n",
        "# Normalize value to [0, 1]\n",
        "X_train /= 255\n",
        "X_test /= 255\n",
        "\n",
        "# Transform lables to one-hot encoding\n",
        "y_tr = np_utils.to_categorical(y_train, 10)\n",
        "y_te = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "# Reshape the dataset into 4D array\n",
        "X_tr = X_train.reshape(X_train.shape[0], 28,28,1)\n",
        "X_te = X_test.reshape(X_test.shape[0], 28,28,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nKp-TbA8DEsY"
      },
      "source": [
        "\n",
        "Create a new instance of a model object using sequential model API. Then add layers to the neural network as per LeNet-5 architecture. Finally, compile the model with the ``categorical_crossentropy`` loss function and SGD algorithm combined with Nesterov momentum. When compiling the model, add ``metrics=[‘accuracy’]`` to calculate the accuracy of the model.\n",
        "\n",
        "**We make the following changes on the original LeNet-5:**\n",
        "\n",
        "- use ReLU activation instead of tanh\n",
        "\n",
        "- use max pooling instead of average pooling"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Conv2D, MaxPool2D, Flatten, ZeroPadding2D, Dense\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras import optimizers"
      ],
      "metadata": {
        "id": "GYc-rym9JJIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "75ZzOuCl6U6T"
      },
      "outputs": [],
      "source": [
        "def lenet5():\n",
        "  model = Sequential()\n",
        "  # C1 Convolutional Layer\n",
        "    \n",
        "  model.add(ZeroPadding2D(padding=(2, 2)))\n",
        "\n",
        "  model.add(Conv2D(filters = 6, kernel_size=(5, 5), strides=1, activation='relu', input_shape=(28,28,1)))\n",
        "  # S2 Pooling Layer\n",
        "  model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # C3 Convolutional Layer\n",
        "  model.add(Conv2D(filters = 16, kernel_size=(5, 5), strides=1, activation='relu'))\n",
        "\n",
        "  # S4 Pooling Layer\n",
        "  model.add(MaxPool2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "  # C5 Fully Connected Convolutional Layer\n",
        "  model.add(Conv2D(filters = 120, kernel_size=(5, 5), strides=1, activation='relu'))\n",
        "    \n",
        "  #Flatten the CNN output so that we can connect it with fully-connected layers\n",
        "  model.add(Flatten())\n",
        "  \n",
        "  # FC6 Fully Connected Layer\n",
        "  model.add(Dense(units = 84, activation='relu'))\n",
        "\n",
        "  # Output Layer with softmax activation\n",
        "  model.add(Dense(units = 10, activation='softmax'))\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer = optimizers.SGD(learning_rate = 0.02, momentum=0.9, nesterov=True), metrics=['accuracy'])\n",
        "\n",
        "  # Or, train using Adam algorithm  \n",
        " #  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])  \n",
        "  return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSsFW9op2AtV"
      },
      "source": [
        "Set up the callbacks for checkpoint and early stopping"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yY4YMVDC0kGg"
      },
      "outputs": [],
      "source": [
        "path_checkpoint = \"lenet5_checkpoint.h5\"\n",
        "es_callback = EarlyStopping(monitor=\"val_accuracy\", patience=7)\n",
        "\n",
        "modelckpt_callback = ModelCheckpoint(\n",
        "    monitor=\"val_accuracy\",\n",
        "    filepath=path_checkpoint,\n",
        "    verbose=1,\n",
        "    save_weights_only=True,\n",
        "    save_best_only=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AmA39vqADQXe"
      },
      "source": [
        "Training and model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cumsgYh9A9u6",
        "outputId": "c3d82ef4-3195-4b83-e9f7-35a779773cb6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "600/600 - 32s - loss: 0.2709 - accuracy: 0.9154 - val_loss: 0.0664 - val_accuracy: 0.9773\n",
            "\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.97730, saving model to lenet5_checkpoint.h5\n",
            "Epoch 2/50\n",
            "600/600 - 2s - loss: 0.0644 - accuracy: 0.9804 - val_loss: 0.0447 - val_accuracy: 0.9855\n",
            "\n",
            "Epoch 00002: val_accuracy improved from 0.97730 to 0.98550, saving model to lenet5_checkpoint.h5\n",
            "Epoch 3/50\n",
            "600/600 - 2s - loss: 0.0478 - accuracy: 0.9851 - val_loss: 0.0367 - val_accuracy: 0.9879\n",
            "\n",
            "Epoch 00003: val_accuracy improved from 0.98550 to 0.98790, saving model to lenet5_checkpoint.h5\n",
            "Epoch 4/50\n",
            "600/600 - 2s - loss: 0.0376 - accuracy: 0.9880 - val_loss: 0.0423 - val_accuracy: 0.9861\n",
            "\n",
            "Epoch 00004: val_accuracy did not improve from 0.98790\n",
            "Epoch 5/50\n",
            "600/600 - 2s - loss: 0.0318 - accuracy: 0.9894 - val_loss: 0.0336 - val_accuracy: 0.9879\n",
            "\n",
            "Epoch 00005: val_accuracy did not improve from 0.98790\n",
            "Epoch 6/50\n",
            "600/600 - 2s - loss: 0.0276 - accuracy: 0.9913 - val_loss: 0.0434 - val_accuracy: 0.9872\n",
            "\n",
            "Epoch 00006: val_accuracy did not improve from 0.98790\n",
            "Epoch 7/50\n",
            "600/600 - 2s - loss: 0.0224 - accuracy: 0.9929 - val_loss: 0.0322 - val_accuracy: 0.9899\n",
            "\n",
            "Epoch 00007: val_accuracy improved from 0.98790 to 0.98990, saving model to lenet5_checkpoint.h5\n",
            "Epoch 8/50\n",
            "600/600 - 2s - loss: 0.0192 - accuracy: 0.9936 - val_loss: 0.0345 - val_accuracy: 0.9885\n",
            "\n",
            "Epoch 00008: val_accuracy did not improve from 0.98990\n",
            "Epoch 9/50\n",
            "600/600 - 2s - loss: 0.0168 - accuracy: 0.9942 - val_loss: 0.0328 - val_accuracy: 0.9910\n",
            "\n",
            "Epoch 00009: val_accuracy improved from 0.98990 to 0.99100, saving model to lenet5_checkpoint.h5\n",
            "Epoch 10/50\n",
            "600/600 - 2s - loss: 0.0155 - accuracy: 0.9944 - val_loss: 0.0319 - val_accuracy: 0.9903\n",
            "\n",
            "Epoch 00010: val_accuracy did not improve from 0.99100\n",
            "Epoch 11/50\n",
            "600/600 - 2s - loss: 0.0125 - accuracy: 0.9958 - val_loss: 0.0278 - val_accuracy: 0.9911\n",
            "\n",
            "Epoch 00011: val_accuracy improved from 0.99100 to 0.99110, saving model to lenet5_checkpoint.h5\n",
            "Epoch 12/50\n",
            "600/600 - 2s - loss: 0.0115 - accuracy: 0.9959 - val_loss: 0.0306 - val_accuracy: 0.9910\n",
            "\n",
            "Epoch 00012: val_accuracy did not improve from 0.99110\n",
            "Epoch 13/50\n",
            "600/600 - 2s - loss: 0.0097 - accuracy: 0.9966 - val_loss: 0.0397 - val_accuracy: 0.9890\n",
            "\n",
            "Epoch 00013: val_accuracy did not improve from 0.99110\n",
            "Epoch 14/50\n",
            "600/600 - 2s - loss: 0.0107 - accuracy: 0.9964 - val_loss: 0.0377 - val_accuracy: 0.9890\n",
            "\n",
            "Epoch 00014: val_accuracy did not improve from 0.99110\n",
            "Epoch 15/50\n",
            "600/600 - 2s - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0326 - val_accuracy: 0.9918\n",
            "\n",
            "Epoch 00015: val_accuracy improved from 0.99110 to 0.99180, saving model to lenet5_checkpoint.h5\n",
            "Epoch 16/50\n",
            "600/600 - 2s - loss: 0.0051 - accuracy: 0.9984 - val_loss: 0.0339 - val_accuracy: 0.9913\n",
            "\n",
            "Epoch 00016: val_accuracy did not improve from 0.99180\n",
            "Epoch 17/50\n",
            "600/600 - 2s - loss: 0.0059 - accuracy: 0.9978 - val_loss: 0.0590 - val_accuracy: 0.9869\n",
            "\n",
            "Epoch 00017: val_accuracy did not improve from 0.99180\n",
            "Epoch 18/50\n",
            "600/600 - 2s - loss: 0.0079 - accuracy: 0.9973 - val_loss: 0.0374 - val_accuracy: 0.9907\n",
            "\n",
            "Epoch 00018: val_accuracy did not improve from 0.99180\n",
            "Epoch 19/50\n",
            "600/600 - 2s - loss: 0.0043 - accuracy: 0.9985 - val_loss: 0.0394 - val_accuracy: 0.9900\n",
            "\n",
            "Epoch 00019: val_accuracy did not improve from 0.99180\n",
            "Epoch 20/50\n",
            "600/600 - 2s - loss: 0.0051 - accuracy: 0.9985 - val_loss: 0.0362 - val_accuracy: 0.9917\n",
            "\n",
            "Epoch 00020: val_accuracy did not improve from 0.99180\n",
            "Epoch 21/50\n",
            "600/600 - 2s - loss: 0.0035 - accuracy: 0.9990 - val_loss: 0.0399 - val_accuracy: 0.9904\n",
            "\n",
            "Epoch 00021: val_accuracy did not improve from 0.99180\n",
            "Epoch 22/50\n",
            "600/600 - 2s - loss: 0.0055 - accuracy: 0.9982 - val_loss: 0.0416 - val_accuracy: 0.9908\n",
            "\n",
            "Epoch 00022: val_accuracy did not improve from 0.99180\n"
          ]
        }
      ],
      "source": [
        "model = lenet5()\n",
        "history = model.fit(X_tr, y_tr, validation_data=(X_te, y_te), \n",
        "          epochs=50, batch_size=100, \n",
        "          callbacks=[es_callback, modelckpt_callback], \n",
        "          verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRQW5zb60eIA",
        "outputId": "3a7a9eb2-bafc-426b-fc6c-22f5712f6015"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Best validation accuracy: 99.18%\n"
          ]
        }
      ],
      "source": [
        "# load the saved weights \n",
        "model.load_weights(path_checkpoint)\n",
        "scores = model.evaluate(X_te, y_te, verbose=0)\n",
        "print(\"\\n Best validation accuracy: %.2f%%\" % (scores[1]*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7VmAg1qLr5DZ"
      },
      "source": [
        "Let's check out the model size of LeNet-5:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llMRf8V_4IA0",
        "outputId": "df83796a-c68d-4a62-a88d-62efd8e37aa3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d_2 (ZeroPaddin (None, 32, 32, 1)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 28, 28, 6)         156       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 14, 14, 6)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 10, 10, 16)        2416      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 5, 5, 16)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 1, 1, 120)         48120     \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 120)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 84)                10164     \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 61,706\n",
            "Trainable params: 61,706\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A9Mp9bGm_JAs"
      },
      "source": [
        "Although the number of trainable parameters in LeNet-5 is only 1/10 of that in the two-dense-layer network, it achieves higher validation accuracy. This is due to the power of convolutional layers."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIVZjYBBS0NK"
      },
      "source": [
        "**Visualize the Training Process**\n",
        "\n",
        "We will visualize the training process by plotting the training accuracy and loss after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "tVErwZYKJMox"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "TNHIFkhZS-k7",
        "outputId": "da21897f-f889-4ef6-d112-3419bbb864b2"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Accuracy')"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot([None] + history.history['accuracy'], 'o-')\n",
        "ax.plot([None] + history.history['val_accuracy'], 'x-')\n",
        "# Plot legend and use the best location automatically: loc = 0.\n",
        "ax.legend(['Train Acc', 'Validation Acc'], loc = 0)\n",
        "ax.set_title('Training/Validation acc per Epoch')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Accuracy')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "ZwbkoWDrUZG0",
        "outputId": "1a973c7e-ce9f-4d05-d2e3-425e698bddf5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Loss')"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "fig, ax = plt.subplots()\n",
        "ax.plot([None] + history.history['loss'], 'o-')\n",
        "ax.plot([None] + history.history['val_loss'], 'x-')\n",
        "# Plot legend and use the best location automatically: loc = 0.\n",
        "ax.legend(['Train Loss', 'Validation Loss'], loc = 0)\n",
        "ax.set_title('Training/Validation Loss per Epoch')\n",
        "ax.set_xlabel('Epoch')\n",
        "ax.set_ylabel('Loss')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skKNtdaZ943Y"
      },
      "source": [
        "#### Save and load model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5auOal-Or5Da",
        "outputId": "8f67b9cd-13f3-430c-d32d-2f8a0cb91e56"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: lenet5/assets\n"
          ]
        }
      ],
      "source": [
        "model.save('lenet5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q1lLzGFQuP_W"
      },
      "outputs": [],
      "source": [
        "loaded_model = tf.keras.models.load_model(\"lenet5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oI60oFugvHP9"
      },
      "source": [
        "Check the test accuracy of the saved model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-stQEYluynu",
        "outputId": "7bc0c8b6-838f-4ddd-d9bc-1ab25d754571"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " Testing/Validation accuracy of the saved model: 99.18%\n"
          ]
        }
      ],
      "source": [
        "scores = loaded_model.evaluate(X_te, y_te, verbose=0)\n",
        "print(\"\\n Testing/Validation accuracy of the saved model: %.2f%%\" % (scores[1]*100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}